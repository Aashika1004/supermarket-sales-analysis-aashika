Introduction:
    Hello! My name is Aashika, and Iâ€™m a final-year university student pursuing a Bachelor of Science in Computer Science (Cybersecurity).
    This mini project was a way to help me get more familiarized with Pandas, Matplotlib and Seaborn while also revisiting
    core Python skills!

# [Log Entry 1] - Grouping of Multiple columns
 Tried to print grouped data using:
    grouped_data = df.groupby(['Category', 'Sub-Category', 'Sales'])
    print(grouped_data)
 Expectation: Would print the grouped categories in a dataframe
 Result: <pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000229573A4590>

 Lesson learnt: .groupby() only creates a GroupBy Object, so when printed python returns the memory address of the object.
                Always follow up with an aggregation method -> ex: mean(), mode(), sum() etc.


# [Log Entry 2] - Sales Aggregation
 Tried using '.value_counts()' to calculate total sales per product category
 Expectation: Would print the dataframe with the required columns and total sales data
 Result: Printed the count of occurrences, not sales totals, output was far too large.
 Final working solution (used in main code):
    - Grouped by Category and Sub-Category.
    - Followed up with a .sum() function used on the 'Sales ($-USD)' column.
    - Code: df.groupby(['Category', 'Sub-Category'])['Sales ($-USD)'].sum().reset_index()

 Lesson learnt: Use groupby + sum for aggregating numerical values, value_counts for counting occurrences.


# [Log Entry 3] -> Analyze total sales per product category and sub-category.
Grouped the dataset by Category and Sub-Category and calculated the total sales (using .sum()) for each group.
This helped me identify which specific product segments would produce the most revenue.
From the result, it's clear that the highest sales per product category and sub-category are:
    1. Furniture -> Chairs -> $328,449.10
    2. Office Supplies -> Storage -> $223,843.61
    3. Technology -> Phones -> $330,007.05

# [Log Entry 4] - Incorrect Sorting Logic
 Tried using the following code to get the top-selling product in each state (not included in main code):
    task_2_df = df.groupby('State','Sub-Category')['Sales'].sum().max()
    print(task_2_df)
 Result: This only returned a single maximum value, and not one product per state. My logic itself was incorrectly applied
         as I realized max doesn't return the top-selling product per grouped category (oops)
 Lesson learnt: Use .sort_values() (with ascending order of State and descending order of Sales) to properly sort the grouped dataset.
                Then, work with that sorted data to extract the top item per state.

# [Log Entry 5] - Finding only the top-performing sub-category, based on total sales, for each state
I used .groupby() on State and Sub-Category and then summed the sales using .sum(). This gave me the total revenue each
sub-category made within every state.
To find the top sub-category in each state:
    1. I sorted the result by State (A-Z) and then Sales ($-USD) (descending order).
    2. Dropped all duplicates but the first sub-category per state using .drop_duplicates().
       (basically one sub-category shown per state)
From the results, this helped me identify what sells best in each state, which could be useful for developing
location-specific sales strategies!

# [Log Entry 6] -
I counted the number of orders for each shipment mode using .value_counts() and set "normalize=True" to get the proportion
of each mode, then multiplied that by 100 to get the percentages for better readability.
Then, I created a pie chart using Matplotlib to visualize the share of each shipment mode.

From the results, it is clear that Standard Class has the highest percentage (59.72%) of shipments, First Class and Second Class
have similar shares at 15.39% and 19.46%, respectively, while Same Day shipping has the lowest percentage at 5.43%.
Thus, this suggests that customers seem to prefer Standard Shipping, so it could be worth reconsidering the Same Day shipping option,
as it is used very less frequently.

# [Log Entry 7] - Analyzing the Corporate vs Consumer segment of customers
I used two different means of analyzing data:
    1. Total sales per segment (using .sum())
        This gave me insights on how the Consumer, Corporate and Home Office segments brought revenue to the supermarket.
        From the data it is clear that the highest revenue comes from Consumers, followed by Corporate and then lastly
        by Home Offices.
    2. The Average sales per segment (using .mean())
        This gave me insights on how much approximately on a single order did each segment spend.
        From the data it is clear that on average, Home Offices place higher value orders, even if their total sales
        are among the lowest.
        Consumers have the lowest average order value, which indicates that while their individual purchases might be smaller,
        they are huge in numbers and thus make up the highest total sales overall.

# [Log Entry 8] - Identify top-performing sub-categories/products
From the result it is clear that the top-selling sub-category is Phones, followed by Chairs and Storage.
And niche accessories like Envelopes, Labels and Fasteners were the lowest selling items, so these
could items could be replaced with some other new items.
# [Log Entry 9] - Incorrect use of trying to apply multiple aggerate function to different columns
Tried using the following codes to get the mean of 'Profit' column and sum of 'Sales' column:
    1.task_6_df_grouped = df.groupby('Region')['Profit'].mean()['Sales'].sum().reset_index()
Expectation: That it would apply the right function to each column separately.
Result: Syntax error, the code couldn't run and exited with code 1
Lesson learnt: Looked into how to apply different aggregation functions to different columns. Turns out, you need to use
               a dictionary, with the column name as the key and the aggregate function as the value, and then passing this
               dictionary to the .agg() function, gives the correct result.

# [Log Entry 10] - Regional Profitability Analysis
I analyzed data in two aspects:
    1. Average Profit and Total Sales by Region
       I grouped the data by 'Region' and calculated the average Profit(.mean()) and total Sales(.sum()) using .agg().
       This helped me understand how profitable each sale is on average.
       From the results, the region with the highest profit(33.85) and the highest sales is the West region.
       The Central region showed the lowest profit (17.09) but still has a good amount of sales. This could mean that there         are some pricing challenges faced by the Central region, despite having significant total sales.
    2. Profit Margin Analysis
       I calculated the profit margin to gain insights into how much money was retained as profit from
       the supermarket's revenue. Revenue refers to the total amount of sales or income generated by selling items.
       I did this by using the .sum() aggregation function on both the Profit and Sales columns, and then created a
       new column, "Profit Margin", calculated as Profit/Sales, which gives the percentage of profit retained.
       From the results, the region with the highest profit margin of 15% is the West region, and the lowest is
       the Central region with just 8%. This further justifies that the Central region is underperforming not only
       in average profit but also in profit margins.

From this analysis, it is clear that the Central region needs urgent modifications, whether in pricing strategies,
discount policies, or operational efficiency.
